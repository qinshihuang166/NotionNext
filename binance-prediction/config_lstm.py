"""
LSTM æ¨¡å‹é…ç½®æ–‡ä»¶
LSTM Model Configuration

è¿™ä¸ªæ–‡ä»¶åŒ…å«æ‰€æœ‰å¯è°ƒæ•´çš„è¶…å‚æ•°å’Œé…ç½®é€‰é¡¹
This file contains all tunable hyperparameters and configuration options

ä½œè€…: qinshihuang166
æ—¥æœŸ: 2024
"""

import os
from typing import Dict, List, Tuple

# ============================================
# æ•°æ®é…ç½® / Data Configuration
# ============================================

class DataConfig:
    """æ•°æ®è·å–å’Œå¤„ç†é…ç½®"""
    
    # Binance API é…ç½®
    SYMBOL = 'BTCUSDT'  # äº¤æ˜“å¯¹ / Trading pair
    INTERVAL = '1h'  # Kçº¿é—´éš”: 1m, 5m, 15m, 1h, 4h, 1d / Candlestick interval
    LOOKBACK_DAYS = 365  # è·å–å¤šå°‘å¤©çš„å†å²æ•°æ® / Days of historical data
    
    # æ•°æ®è·¯å¾„é…ç½®
    DATA_DIR = 'data'  # åŸå§‹æ•°æ®ç›®å½•
    LSTM_DATA_DIR = 'lstm_data'  # LSTMå¤„ç†åçš„æ•°æ®ç›®å½•
    RAW_DATA_FILE = f'{DATA_DIR}/{SYMBOL}_raw_data.csv'
    PROCESSED_DATA_FILE = f'{LSTM_DATA_DIR}/{SYMBOL}_processed.csv'
    
    # æ•°æ®åˆ’åˆ†æ¯”ä¾‹
    TRAIN_RATIO = 0.70  # 70% è®­ç»ƒé›†
    VAL_RATIO = 0.15    # 15% éªŒè¯é›†
    TEST_RATIO = 0.15   # 15% æµ‹è¯•é›†
    
    # ç‰¹å¾å·¥ç¨‹é…ç½®
    USE_TECHNICAL_INDICATORS = True  # æ˜¯å¦ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡
    TECHNICAL_INDICATORS = [
        'RSI',           # ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡
        'MACD',          # ç§»åŠ¨å¹³å‡æ”¶æ•›æ•£åº¦
        'MACD_signal',   # MACDä¿¡å·çº¿
        'MACD_hist',     # MACDæŸ±çŠ¶å›¾ (MACD - Signal)
        'BB_upper',      # å¸ƒæ—å¸¦ä¸Šè½¨
        'BB_middle',     # å¸ƒæ—å¸¦ä¸­è½¨
        'BB_lower',      # å¸ƒæ—å¸¦ä¸‹è½¨
        'EMA_12',        # 12æœŸæŒ‡æ•°ç§»åŠ¨å¹³å‡
        'EMA_26',        # 26æœŸæŒ‡æ•°ç§»åŠ¨å¹³å‡
        'ATR',           # å¹³å‡çœŸå®èŒƒå›´
        'OBV',           # èƒ½é‡æ½®
    ]
    
    # æ—¶é—´åºåˆ—çª—å£é…ç½®
    TIME_STEPS = 60  # ä½¿ç”¨è¿‡å»60ä¸ªæ—¶é—´ç‚¹é¢„æµ‹ä¸‹ä¸€ä¸ª / Use past 60 timesteps to predict next one
    PREDICTION_HORIZON = 1  # é¢„æµ‹æœªæ¥1ä¸ªæ—¶é—´ç‚¹ / Predict 1 timestep ahead
    
    # æ•°æ®å½’ä¸€åŒ–
    SCALER_TYPE = 'MinMaxScaler'  # å¯é€‰: 'MinMaxScaler', 'StandardScaler'
    FEATURE_RANGE = (0, 1)  # MinMaxScalerçš„èŒƒå›´


# ============================================
# æ¨¡å‹é…ç½® / Model Configuration
# ============================================

class ModelConfig:
    """LSTM æ¨¡å‹æ¶æ„é…ç½®"""
    
    # æ¨¡å‹ç±»å‹
    MODEL_TYPE = 'BiLSTM'  # å¯é€‰: 'LSTM', 'BiLSTM', 'GRU', 'BiGRU'
    
    # ç½‘ç»œæ¶æ„
    # å±‚é…ç½®æ ¼å¼: [ç¬¬ä¸€å±‚å•å…ƒæ•°, ç¬¬äºŒå±‚å•å…ƒæ•°, ...]
    LSTM_UNITS = [128, 64, 32]  # ä¸‰å±‚LSTMï¼Œæ¯å±‚çš„å•å…ƒæ•°
    DENSE_UNITS = [16]  # Denseå±‚é…ç½®
    
    # Dropout é…ç½®ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
    DROPOUT_RATE = 0.2  # Dropoutæ¯”ä¾‹ (0.2 = 20%)
    RECURRENT_DROPOUT = 0.1  # LSTMå†…éƒ¨çš„Dropout
    
    # æ­£åˆ™åŒ–é…ç½®ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
    USE_L1_REGULARIZATION = False  # æ˜¯å¦ä½¿ç”¨L1æ­£åˆ™åŒ–
    USE_L2_REGULARIZATION = True   # æ˜¯å¦ä½¿ç”¨L2æ­£åˆ™åŒ–
    L1_LAMBDA = 0.0001  # L1æ­£åˆ™åŒ–ç³»æ•°
    L2_LAMBDA = 0.001   # L2æ­£åˆ™åŒ–ç³»æ•°
    
    # BatchNormalization
    USE_BATCH_NORMALIZATION = True  # æ˜¯å¦ä½¿ç”¨æ‰¹æ ‡å‡†åŒ–
    
    # æ¿€æ´»å‡½æ•°
    LSTM_ACTIVATION = 'tanh'  # LSTMæ¿€æ´»å‡½æ•°
    DENSE_ACTIVATION = 'relu'  # Denseå±‚æ¿€æ´»å‡½æ•°
    OUTPUT_ACTIVATION = 'linear'  # è¾“å‡ºå±‚æ¿€æ´»å‡½æ•° (å›å½’é—®é¢˜ç”¨linear)
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    LOSS_FUNCTION = 'mse'  # å¯é€‰: 'mse', 'mae', 'huber'
    OPTIMIZER = 'adam'  # å¯é€‰: 'adam', 'rmsprop', 'sgd'
    LEARNING_RATE = 0.001  # åˆå§‹å­¦ä¹ ç‡
    
    # è¯„ä¼°æŒ‡æ ‡
    METRICS = ['mae', 'mse']  # è®­ç»ƒæ—¶è·Ÿè¸ªçš„æŒ‡æ ‡


# ============================================
# è®­ç»ƒé…ç½® / Training Configuration
# ============================================

class TrainingConfig:
    """æ¨¡å‹è®­ç»ƒé…ç½®"""
    
    # åŸºç¡€è®­ç»ƒå‚æ•°
    EPOCHS = 100  # æœ€å¤§è®­ç»ƒè½®æ•°
    BATCH_SIZE = 32  # æ‰¹å¤§å° (æ ¹æ®å†…å­˜è°ƒæ•´: 16, 32, 64, 128)
    VALIDATION_SPLIT = 0.0  # ä¸ä½¿ç”¨ï¼Œæˆ‘ä»¬æ‰‹åŠ¨åˆ’åˆ†äº†éªŒè¯é›†
    SHUFFLE = False  # æ—¶é—´åºåˆ—æ•°æ®ä¸æ‰“ä¹±é¡ºåº
    
    # æ—©åœé…ç½®ï¼ˆEarly Stoppingï¼‰
    USE_EARLY_STOPPING = True  # æ˜¯å¦ä½¿ç”¨æ—©åœ
    EARLY_STOPPING_PATIENCE = 15  # å¤šå°‘ä¸ªepochæ²¡æœ‰æ”¹å–„å°±åœæ­¢
    EARLY_STOPPING_MIN_DELTA = 0.0001  # æœ€å°æ”¹å–„å¹…åº¦
    EARLY_STOPPING_MONITOR = 'val_loss'  # ç›‘æ§çš„æŒ‡æ ‡
    RESTORE_BEST_WEIGHTS = True  # æ¢å¤æœ€ä½³æƒé‡
    
    # å­¦ä¹ ç‡è°ƒæ•´é…ç½®ï¼ˆReduceLROnPlateauï¼‰
    USE_REDUCE_LR = True  # æ˜¯å¦ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡
    REDUCE_LR_FACTOR = 0.5  # å­¦ä¹ ç‡è¡°å‡å› å­
    REDUCE_LR_PATIENCE = 7  # å¤šå°‘ä¸ªepochæ²¡æœ‰æ”¹å–„å°±é™ä½å­¦ä¹ ç‡
    REDUCE_LR_MIN_LR = 1e-7  # æœ€å°å­¦ä¹ ç‡
    REDUCE_LR_MONITOR = 'val_loss'  # ç›‘æ§çš„æŒ‡æ ‡
    
    # æ¨¡å‹æ£€æŸ¥ç‚¹é…ç½®ï¼ˆModelCheckpointï¼‰
    USE_MODEL_CHECKPOINT = True  # æ˜¯å¦ä¿å­˜æœ€ä½³æ¨¡å‹
    CHECKPOINT_MONITOR = 'val_loss'  # ç›‘æ§çš„æŒ‡æ ‡
    CHECKPOINT_MODE = 'min'  # 'min' è¡¨ç¤ºæŒ‡æ ‡è¶Šå°è¶Šå¥½
    CHECKPOINT_SAVE_BEST_ONLY = True  # åªä¿å­˜æœ€ä½³æ¨¡å‹
    CHECKPOINT_SAVE_WEIGHTS_ONLY = False  # ä¿å­˜å®Œæ•´æ¨¡å‹
    
    # è®­ç»ƒæ—¥å¿—é…ç½®
    VERBOSE = 1  # è®­ç»ƒæ—¶çš„è¾“å‡ºè¯¦ç»†ç¨‹åº¦: 0=é™é»˜, 1=è¿›åº¦æ¡, 2=æ¯ä¸ªepochä¸€è¡Œ
    USE_TENSORBOARD = False  # æ˜¯å¦ä½¿ç”¨TensorBoard (å¯é€‰)
    
    # GPUé…ç½®
    USE_GPU = True  # æ˜¯å¦å°è¯•ä½¿ç”¨GPU
    GPU_MEMORY_GROWTH = True  # åŠ¨æ€åˆ†é…GPUå†…å­˜
    MIXED_PRECISION = False  # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆéœ€è¦GPUï¼‰


# ============================================
# è·¯å¾„é…ç½® / Path Configuration
# ============================================

class PathConfig:
    """æ–‡ä»¶è·¯å¾„é…ç½®"""
    
    # åŸºç¡€ç›®å½•
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    DATA_DIR = os.path.join(BASE_DIR, 'data')
    LSTM_DATA_DIR = os.path.join(BASE_DIR, 'lstm_data')
    MODELS_DIR = os.path.join(BASE_DIR, 'lstm_models')
    RESULTS_DIR = os.path.join(BASE_DIR, 'lstm_results')
    LOGS_DIR = os.path.join(BASE_DIR, 'logs')
    
    # æ¨¡å‹ä¿å­˜è·¯å¾„
    MODEL_NAME = f'{DataConfig.SYMBOL}_lstm_model.h5'
    MODEL_PATH = os.path.join(MODELS_DIR, MODEL_NAME)
    CHECKPOINT_PATH = os.path.join(MODELS_DIR, f'{DataConfig.SYMBOL}_checkpoint.h5')
    
    # Scalerä¿å­˜è·¯å¾„
    SCALER_PATH = os.path.join(MODELS_DIR, f'{DataConfig.SYMBOL}_scaler.pkl')
    
    # ç»“æœä¿å­˜è·¯å¾„
    TRAINING_HISTORY_PATH = os.path.join(RESULTS_DIR, 'training_history.csv')
    PREDICTIONS_PATH = os.path.join(RESULTS_DIR, 'predictions.csv')
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    @staticmethod
    def create_directories():
        """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•"""
        for dir_path in [
            PathConfig.DATA_DIR,
            PathConfig.LSTM_DATA_DIR,
            PathConfig.MODELS_DIR,
            PathConfig.RESULTS_DIR,
            PathConfig.LOGS_DIR
        ]:
            os.makedirs(dir_path, exist_ok=True)
            print(f"âœ“ ç›®å½•å·²åˆ›å»º/ç¡®è®¤: {dir_path}")


# ============================================
# é¢„è®¾é…ç½®æ–¹æ¡ˆ / Preset Configurations
# ============================================

class PresetConfigs:
    """é¢„è®¾çš„é…ç½®æ–¹æ¡ˆï¼Œæ–¹ä¾¿å¿«é€Ÿåˆ‡æ¢"""
    
    @staticmethod
    def quick_test():
        """å¿«é€Ÿæµ‹è¯•é…ç½®ï¼ˆå°æ•°æ®é‡ï¼Œå¿«é€Ÿè®­ç»ƒï¼‰"""
        DataConfig.LOOKBACK_DAYS = 90
        DataConfig.TIME_STEPS = 30
        ModelConfig.LSTM_UNITS = [64, 32]
        ModelConfig.DENSE_UNITS = [16]
        TrainingConfig.EPOCHS = 20
        TrainingConfig.BATCH_SIZE = 64
        TrainingConfig.EARLY_STOPPING_PATIENCE = 5
        print("âœ“ å·²åº”ç”¨ã€å¿«é€Ÿæµ‹è¯•ã€‘é…ç½®")
    
    @staticmethod
    def production():
        """ç”Ÿäº§ç¯å¢ƒé…ç½®ï¼ˆå®Œæ•´è®­ç»ƒï¼‰"""
        DataConfig.LOOKBACK_DAYS = 730  # 2å¹´æ•°æ®
        DataConfig.TIME_STEPS = 60
        ModelConfig.LSTM_UNITS = [256, 128, 64]
        ModelConfig.DENSE_UNITS = [32, 16]
        TrainingConfig.EPOCHS = 200
        TrainingConfig.BATCH_SIZE = 32
        TrainingConfig.EARLY_STOPPING_PATIENCE = 20
        print("âœ“ å·²åº”ç”¨ã€ç”Ÿäº§ç¯å¢ƒã€‘é…ç½®")
    
    @staticmethod
    def gpu_optimized():
        """GPUä¼˜åŒ–é…ç½®ï¼ˆå¤§æ‰¹é‡ï¼‰"""
        TrainingConfig.BATCH_SIZE = 128
        TrainingConfig.USE_GPU = True
        TrainingConfig.MIXED_PRECISION = True
        ModelConfig.LSTM_UNITS = [512, 256, 128]
        print("âœ“ å·²åº”ç”¨ã€GPUä¼˜åŒ–ã€‘é…ç½®")
    
    @staticmethod
    def cpu_friendly():
        """CPUå‹å¥½é…ç½®ï¼ˆå°æ‰¹é‡ï¼Œç®€å•æ¨¡å‹ï¼‰"""
        TrainingConfig.BATCH_SIZE = 16
        TrainingConfig.USE_GPU = False
        ModelConfig.LSTM_UNITS = [64, 32]
        ModelConfig.DENSE_UNITS = [16]
        TrainingConfig.EPOCHS = 50
        print("âœ“ å·²åº”ç”¨ã€CPUå‹å¥½ã€‘é…ç½®")


# ============================================
# å¯è§†åŒ–é…ç½® / Visualization Configuration
# ============================================

class VisualizationConfig:
    """å¯è§†åŒ–ç›¸å…³é…ç½®"""
    
    # å›¾è¡¨æ ·å¼
    STYLE = 'seaborn-v0_8-darkgrid'  # matplotlibæ ·å¼
    FIGURE_SIZE = (15, 8)  # å›¾è¡¨å¤§å°
    DPI = 100  # å›¾è¡¨åˆ†è¾¨ç‡
    
    # é¢œè‰²é…ç½®
    TRAIN_COLOR = '#1f77b4'  # è®­ç»ƒé›†é¢œè‰²ï¼ˆè“è‰²ï¼‰
    VAL_COLOR = '#ff7f0e'    # éªŒè¯é›†é¢œè‰²ï¼ˆæ©™è‰²ï¼‰
    TEST_COLOR = '#2ca02c'   # æµ‹è¯•é›†é¢œè‰²ï¼ˆç»¿è‰²ï¼‰
    PRED_COLOR = '#d62728'   # é¢„æµ‹é¢œè‰²ï¼ˆçº¢è‰²ï¼‰
    
    # ä¿å­˜é…ç½®
    SAVE_PLOTS = True  # æ˜¯å¦ä¿å­˜å›¾è¡¨
    PLOT_FORMAT = 'png'  # å›¾è¡¨æ ¼å¼: png, jpg, svg, pdf
    
    # ä¸­æ–‡å­—ä½“æ”¯æŒ
    FONT_FAMILY = 'SimHei'  # ä¸­æ–‡å­—ä½“ï¼ˆé»‘ä½“ï¼‰
    FONT_SIZE = 12


# ============================================
# æ—¥å¿—é…ç½® / Logging Configuration
# ============================================

class LogConfig:
    """æ—¥å¿—é…ç½®"""
    
    # æ—¥å¿—çº§åˆ«
    LOG_LEVEL = 'INFO'  # DEBUG, INFO, WARNING, ERROR, CRITICAL
    
    # æ—¥å¿—æ ¼å¼
    LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    DATE_FORMAT = '%Y-%m-%d %H:%M:%S'
    
    # æ—¥å¿—æ–‡ä»¶
    LOG_FILE = os.path.join(PathConfig.LOGS_DIR, 'lstm_training.log')
    MAX_LOG_SIZE = 10 * 1024 * 1024  # 10MB
    BACKUP_COUNT = 5  # ä¿ç•™5ä¸ªå¤‡ä»½æ—¥å¿—


# ============================================
# è¾…åŠ©å‡½æ•° / Helper Functions
# ============================================

def print_config_summary():
    """æ‰“å°å½“å‰é…ç½®æ‘˜è¦"""
    print("=" * 60)
    print("LSTM æ¨¡å‹é…ç½®æ‘˜è¦ / LSTM Model Configuration Summary")
    print("=" * 60)
    print(f"\nğŸ“Š æ•°æ®é…ç½®:")
    print(f"  - äº¤æ˜“å¯¹: {DataConfig.SYMBOL}")
    print(f"  - æ—¶é—´é—´éš”: {DataConfig.INTERVAL}")
    print(f"  - å†å²æ•°æ®: {DataConfig.LOOKBACK_DAYS} å¤©")
    print(f"  - æ—¶é—´çª—å£: {DataConfig.TIME_STEPS} ä¸ªæ—¶é—´ç‚¹")
    print(f"  - æ•°æ®åˆ’åˆ†: è®­ç»ƒ{int(DataConfig.TRAIN_RATIO*100)}% / éªŒè¯{int(DataConfig.VAL_RATIO*100)}% / æµ‹è¯•{int(DataConfig.TEST_RATIO*100)}%")
    
    print(f"\nğŸ§  æ¨¡å‹é…ç½®:")
    print(f"  - æ¨¡å‹ç±»å‹: {ModelConfig.MODEL_TYPE}")
    print(f"  - LSTMå±‚: {ModelConfig.LSTM_UNITS}")
    print(f"  - Denseå±‚: {ModelConfig.DENSE_UNITS}")
    print(f"  - Dropout: {ModelConfig.DROPOUT_RATE}")
    print(f"  - æ‰¹æ ‡å‡†åŒ–: {'å¯ç”¨' if ModelConfig.USE_BATCH_NORMALIZATION else 'ç¦ç”¨'}")
    
    print(f"\nğŸ‹ï¸ è®­ç»ƒé…ç½®:")
    print(f"  - æœ€å¤§è½®æ•°: {TrainingConfig.EPOCHS}")
    print(f"  - æ‰¹å¤§å°: {TrainingConfig.BATCH_SIZE}")
    print(f"  - å­¦ä¹ ç‡: {ModelConfig.LEARNING_RATE}")
    print(f"  - æ—©åœ: {'å¯ç”¨' if TrainingConfig.USE_EARLY_STOPPING else 'ç¦ç”¨'} (è€å¿ƒå€¼: {TrainingConfig.EARLY_STOPPING_PATIENCE})")
    print(f"  - å­¦ä¹ ç‡è¡°å‡: {'å¯ç”¨' if TrainingConfig.USE_REDUCE_LR else 'ç¦ç”¨'}")
    print(f"  - GPUåŠ é€Ÿ: {'å°è¯•å¯ç”¨' if TrainingConfig.USE_GPU else 'ç¦ç”¨'}")
    
    print(f"\nğŸ“ è·¯å¾„é…ç½®:")
    print(f"  - æ¨¡å‹ä¿å­˜: {PathConfig.MODEL_PATH}")
    print(f"  - ç»“æœä¿å­˜: {PathConfig.RESULTS_DIR}")
    print("=" * 60)


def get_input_shape(num_features: int) -> Tuple[int, int]:
    """
    è·å–LSTMè¾“å…¥å½¢çŠ¶
    
    Args:
        num_features: ç‰¹å¾æ•°é‡
    
    Returns:
        (time_steps, num_features)
    """
    return (DataConfig.TIME_STEPS, num_features)


def estimate_training_time() -> str:
    """
    ä¼°ç®—è®­ç»ƒæ—¶é—´
    
    Returns:
        é¢„ä¼°çš„è®­ç»ƒæ—¶é—´å­—ç¬¦ä¸²
    """
    # ç²—ç•¥ä¼°ç®—ï¼ˆåŸºäºç»éªŒï¼‰
    epochs = TrainingConfig.EPOCHS
    batch_size = TrainingConfig.BATCH_SIZE
    
    # CPUå¤§çº¦æ¯ä¸ªepoch 20-30ç§’ï¼ŒGPUå¤§çº¦5-10ç§’
    if TrainingConfig.USE_GPU:
        time_per_epoch = 7  # ç§’
        device = "GPU"
    else:
        time_per_epoch = 25  # ç§’
        device = "CPU"
    
    total_seconds = epochs * time_per_epoch
    minutes = total_seconds // 60
    seconds = total_seconds % 60
    
    return f"é¢„è®¡ {minutes} åˆ† {seconds} ç§’ ({device})"


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    print_config_summary()
    print(f"\nâ±ï¸ é¢„è®¡è®­ç»ƒæ—¶é—´: {estimate_training_time()}")
    print(f"\nâœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸï¼")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    PathConfig.create_directories()
