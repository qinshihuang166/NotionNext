"""
LSTM æ¨¡å‹è¯„ä¼°è„šæœ¬ï¼ˆç»¼åˆè¯„ä¼°ï¼‰

åŒ…å«ï¼š
- å›å½’æŒ‡æ ‡ï¼ˆçœŸå®ä»·æ ¼å°ºåº¦ï¼‰
- æ–¹å‘é¢„æµ‹æŒ‡æ ‡ï¼ˆConfusion Matrix / Accuracyï¼‰
- ä¸ç®€å•åŸºçº¿ï¼ˆä¸Šä¸€æ—¶åˆ»ä»·æ ¼ï¼‰å¯¹æ¯”
- å¯è§†åŒ–è¾“å‡º

ä½¿ç”¨ï¼š
    cd binance-prediction
    python scripts/lstm/evaluate.py

ä½œè€…: qinshihuang166
"""

from __future__ import annotations

import argparse
import os
import sys
from datetime import datetime

import numpy as np
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from config_lstm import DataConfig, PathConfig
from utils.lstm_data_processor import LSTMDataProcessor
from utils.lstm_metrics import calc_regression_metrics, calc_direction_metrics, calc_naive_baseline


def _ensure_matplotlib_backend() -> None:
    """ä¿è¯åœ¨æ—  GUI ç¯å¢ƒä¹Ÿèƒ½ä¿å­˜å›¾ç‰‡"""

    import matplotlib

    matplotlib.use('Agg')


def load_model() -> "object":
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""

    import tensorflow as tf

    if not os.path.exists(PathConfig.MODEL_PATH):
        raise FileNotFoundError(
            f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {PathConfig.MODEL_PATH}\n"
            f"è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼špython scripts/lstm/train_lstm.py"
        )

    return tf.keras.models.load_model(PathConfig.MODEL_PATH)


def build_eval_dataset(processor: LSTMDataProcessor) -> dict:
    """æ„å»ºè¯„ä¼°æ‰€éœ€çš„æ•°æ®é›†ï¼ˆåŒ…å« scaled å’Œ real ä¸¤å¥— yï¼‰"""

    # 1. åŸå§‹æ•°æ®
    df_raw = processor.load_raw_data()
    df_raw = processor.clean_data(df_raw)
    df_raw = processor.add_features(df_raw)

    # 2. é€‰æ‹©ç‰¹å¾ï¼ˆåŸå§‹å°ºåº¦ï¼‰
    df_features_real = processor.select_features(df_raw)

    # 3. ä½¿ç”¨è®­ç»ƒæ—¶çš„ scaler åš transform
    processor.load_scaler(PathConfig.SCALER_PATH)
    df_features_scaled = processor.normalize_data(df_features_real, fit=False)

    # 4. æ„å»ºåºåˆ—ï¼ˆX ä½¿ç”¨ scaledï¼‰
    X_all, y_scaled_all = processor.create_sequences(df_features_scaled.values)

    # y_true_realï¼šç”¨çœŸå® close å¯¹é½
    y_real_all = df_features_real['close'].values[DataConfig.TIME_STEPS :]

    # 5. åˆ’åˆ†ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰
    X_train, X_val, X_test, y_train_scaled, y_val_scaled, y_test_scaled = processor.split_data(X_all, y_scaled_all)

    # çœŸå®ä»·æ ¼ä¹ŸæŒ‰åŒæ ·åˆ‡åˆ†
    total = len(y_real_all)
    train_size = int(total * DataConfig.TRAIN_RATIO)
    val_size = int(total * DataConfig.VAL_RATIO)

    y_train_real = y_real_all[:train_size]
    y_val_real = y_real_all[train_size : train_size + val_size]
    y_test_real = y_real_all[train_size + val_size :]

    return {
        'X_train': X_train,
        'X_val': X_val,
        'X_test': X_test,
        'y_train_scaled': y_train_scaled,
        'y_val_scaled': y_val_scaled,
        'y_test_scaled': y_test_scaled,
        'y_train_real': y_train_real,
        'y_val_real': y_val_real,
        'y_test_real': y_test_real,
        'df_features_real': df_features_real,
        'df_features_scaled': df_features_scaled,
    }


def inverse_close(processor: LSTMDataProcessor, close_scaled: np.ndarray) -> np.ndarray:
    """æŠŠ scaled close åå½’ä¸€åŒ–æˆçœŸå®ä»·æ ¼"""

    close_scaled = np.asarray(close_scaled).reshape(-1)
    full = np.zeros((len(close_scaled), len(processor.feature_columns)), dtype=float)
    full[:, 3] = close_scaled
    real = processor.scaler.inverse_transform(full)
    return real[:, 3]


def save_confusion_matrix(cm: np.ndarray, out_path: str) -> None:
    """ä¿å­˜æ··æ·†çŸ©é˜µå›¾ç‰‡"""

    _ensure_matplotlib_backend()

    import matplotlib.pyplot as plt

    fig, ax = plt.subplots(figsize=(5, 4))
    ax.imshow(cm, cmap='Blues')
    ax.set_title('æ¶¨è·Œæ–¹å‘æ··æ·†çŸ©é˜µ')
    ax.set_xlabel('é¢„æµ‹')
    ax.set_ylabel('å®é™…')

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha='center', va='center', color='black')

    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(['è·Œ/ä¸å˜(0)', 'æ¶¨(1)'])
    ax.set_yticklabels(['è·Œ/ä¸å˜(0)', 'æ¶¨(1)'])

    plt.tight_layout()
    plt.savefig(out_path, dpi=150, bbox_inches='tight')
    plt.close()


def main() -> None:
    parser = argparse.ArgumentParser(description='LSTM æ¨¡å‹è¯„ä¼°è„šæœ¬')
    parser.add_argument('--symbol', type=str, default=DataConfig.SYMBOL, help='äº¤æ˜“å¯¹ï¼Œä¾‹å¦‚ BTCUSDT')
    args = parser.parse_args()

    # å½“å‰ç‰ˆæœ¬ï¼šsymbol ä¸»è¦ç”¨äºå±•ç¤ºã€‚è‹¥ä½ è¦è®­ç»ƒå¤šå¸ç§ï¼Œå»ºè®®æ¯ä¸ªå¸ç§å•ç‹¬è®­ç»ƒ/ä¿å­˜æ¨¡å‹ã€‚
    print('=' * 70)
    print('ğŸ“Š LSTM æ¨¡å‹è¯„ä¼°')
    print('=' * 70)
    print(f'äº¤æ˜“å¯¹: {args.symbol}')

    # å‡†å¤‡ç›®å½•
    PathConfig.create_directories()

    # åŠ è½½æ¨¡å‹
    model = load_model()

    # æ„å»ºæ•°æ®
    processor = LSTMDataProcessor()
    data = build_eval_dataset(processor)

    X_test = data['X_test']
    y_test_real = data['y_test_real']

    # æ¨¡å‹é¢„æµ‹ï¼ˆscaledï¼‰
    y_pred_scaled = model.predict(X_test, verbose=0).reshape(-1)

    # è½¬å›çœŸå®ä»·æ ¼
    y_pred_real = inverse_close(processor, y_pred_scaled)

    # è®¡ç®—æŒ‡æ ‡
    reg = calc_regression_metrics(y_test_real, y_pred_real)
    direction = calc_direction_metrics(y_test_real, y_pred_real)

    # åŸºçº¿ï¼šä¸Šä¸€æ—¶åˆ»ä»·æ ¼
    baseline_pred = calc_naive_baseline(y_test_real)
    reg_baseline = calc_regression_metrics(y_test_real, baseline_pred)
    direction_baseline = calc_direction_metrics(y_test_real, baseline_pred)

    # è¾“å‡º
    print('\nâœ… å›å½’æŒ‡æ ‡ï¼ˆçœŸå®ä»·æ ¼å°ºåº¦ï¼‰')
    print(f'  MAE : {reg.mae:.4f}')
    print(f'  RMSE: {reg.rmse:.4f}')
    print(f'  MAPE: {reg.mape:.4f}%')
    print(f'  R2  : {reg.r2:.4f}')

    print('\nâœ… æ–¹å‘æŒ‡æ ‡ï¼ˆæ¶¨è·Œæ–¹å‘ï¼‰')
    print(f'  Accuracy : {direction.accuracy:.4f}')
    print(f'  Precision: {direction.precision:.4f}')
    print(f'  Recall   : {direction.recall:.4f}')
    print(f'  F1       : {direction.f1:.4f}')

    print('\nğŸ“Œ åŸºçº¿å¯¹æ¯”ï¼ˆä¸Šä¸€æ—¶åˆ»ä»·æ ¼ä½œä¸ºé¢„æµ‹ï¼‰')
    print(f'  Baseline MAE : {reg_baseline.mae:.4f}')
    print(f'  Baseline RMSE: {reg_baseline.rmse:.4f}')
    print(f'  Baseline Acc : {direction_baseline.accuracy:.4f}')

    # ä¿å­˜ç»“æœ
    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    out_dir = PathConfig.RESULTS_DIR

    metrics_path = os.path.join(out_dir, f'eval_metrics_{ts}.json')
    pd.DataFrame(
        [
            {
                'model': 'LSTM',
                'mae': reg.mae,
                'mse': reg.mse,
                'rmse': reg.rmse,
                'mape': reg.mape,
                'r2': reg.r2,
                'direction_accuracy': direction.accuracy,
                'direction_precision': direction.precision,
                'direction_recall': direction.recall,
                'direction_f1': direction.f1,
            },
            {
                'model': 'Baseline(prev_close)',
                'mae': reg_baseline.mae,
                'mse': reg_baseline.mse,
                'rmse': reg_baseline.rmse,
                'mape': reg_baseline.mape,
                'r2': reg_baseline.r2,
                'direction_accuracy': direction_baseline.accuracy,
                'direction_precision': direction_baseline.precision,
                'direction_recall': direction_baseline.recall,
                'direction_f1': direction_baseline.f1,
            },
        ]
    ).to_json(metrics_path, orient='records', force_ascii=False, indent=2)

    print(f'\nğŸ’¾ è¯„ä¼°æŒ‡æ ‡å·²ä¿å­˜: {metrics_path}')

    cm_path = os.path.join(out_dir, f'confusion_matrix_{ts}.png')
    save_confusion_matrix(direction.cm, cm_path)
    print(f'ğŸ–¼ï¸ æ··æ·†çŸ©é˜µå·²ä¿å­˜: {cm_path}')

    pred_path = os.path.join(out_dir, f'predictions_real_{ts}.csv')
    pd.DataFrame({'y_true': y_test_real, 'y_pred': y_pred_real}).to_csv(pred_path, index=False)
    print(f'ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜: {pred_path}')


if __name__ == '__main__':
    main()
