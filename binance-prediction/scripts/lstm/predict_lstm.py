"""
LSTMä»·æ ¼é¢„æµ‹è„šæœ¬
LSTM Price Prediction Script

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œä»·æ ¼é¢„æµ‹
Use trained model to make price predictions

ä½œè€…: qinshihuang166
"""

import os
import sys
import argparse
import numpy as np
import pandas as pd
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from config_lstm import DataConfig, PathConfig
from utils.lstm_data_processor import LSTMDataProcessor
from utils.binance_client import BinanceUtility
import warnings
warnings.filterwarnings('ignore')


def load_model_and_scaler():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œscaler"""
    import tensorflow as tf
    
    model_path = PathConfig.MODEL_PATH
    scaler_path = PathConfig.SCALER_PATH
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("\nğŸ’¡ è¯·å…ˆè®­ç»ƒæ¨¡å‹:")
        print("   python scripts/lstm/train_lstm.py")
        sys.exit(1)
    
    if not os.path.exists(scaler_path):
        print(f"âŒ Scaleræ–‡ä»¶ä¸å­˜åœ¨: {scaler_path}")
        print("\nğŸ’¡ è¯·å…ˆè®­ç»ƒæ¨¡å‹:")
        print("   python scripts/lstm/train_lstm.py")
        sys.exit(1)
    
    # åŠ è½½æ¨¡å‹
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
    model = tf.keras.models.load_model(model_path)
    
    # åŠ è½½scaler
    print(f"ğŸ“‚ åŠ è½½Scaler: {scaler_path}")
    processor = LSTMDataProcessor()
    processor.load_scaler(scaler_path)
    
    return model, processor


def prepare_recent_data(processor, symbol, interval, time_steps):
    """å‡†å¤‡æœ€è¿‘çš„æ•°æ®ç”¨äºé¢„æµ‹"""
    print(f"\nğŸ“¥ è·å–æœ€æ–°æ•°æ®...")
    
    # è·å–æœ€æ–°æ•°æ®
    client = BinanceUtility()
    
    # éœ€è¦è·å–è¶³å¤Ÿçš„æ•°æ®æ¥æ„å»ºæ—¶é—´çª—å£ + è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    # æŠ€æœ¯æŒ‡æ ‡æœ€å¤šéœ€è¦200ä¸ªç‚¹ï¼Œæ—¶é—´çª—å£éœ€è¦time_stepsä¸ªç‚¹
    lookback_hours = max(300, time_steps + 200)
    start_time = datetime.now() - timedelta(hours=lookback_hours)
    start_str = start_time.strftime("%d %b, %Y")
    
    df = client.fetch_historical_data(symbol, interval, start_str)
    
    if df is None or df.empty:
        print("âŒ æ— æ³•è·å–æ•°æ®")
        sys.exit(1)
    
    print(f"âœ“ è·å–äº† {len(df)} ä¸ªæ•°æ®ç‚¹")
    print(f"  æ—¶é—´èŒƒå›´: {df['timestamp'].min()} åˆ° {df['timestamp'].max()}")
    
    # æ•°æ®å¤„ç†
    df = processor.clean_data(df)
    df = processor.add_features(df)
    df = processor.select_features(df)
    
    # å½’ä¸€åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶çš„scalerï¼‰
    df_normalized = processor.normalize_data(df, fit=False)
    
    # å–æœ€åtime_stepsä¸ªç‚¹
    recent_data = df_normalized.values[-time_steps:]
    
    # é‡å¡‘ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼: (1, time_steps, features)
    X = recent_data.reshape(1, time_steps, recent_data.shape[1])
    
    return X, df


def predict_next_price(model, X, processor):
    """é¢„æµ‹ä¸‹ä¸€ä¸ªä»·æ ¼"""
    # æ¨¡å‹é¢„æµ‹ï¼ˆå½’ä¸€åŒ–å€¼ï¼‰
    prediction_scaled = model.predict(X, verbose=0)
    
    # åå½’ä¸€åŒ–ï¼ˆå‡è®¾closeæ˜¯ç¬¬4ä¸ªç‰¹å¾ï¼Œç´¢å¼•3ï¼‰
    # åˆ›å»ºä¸€ä¸ªå…¨é›¶æ•°ç»„ï¼Œåªå¡«å…¥é¢„æµ‹å€¼åˆ°closeçš„ä½ç½®
    full_prediction = np.zeros((1, len(processor.feature_columns)))
    full_prediction[0, 3] = prediction_scaled[0, 0]  # closeåœ¨ç´¢å¼•3
    
    # åå½’ä¸€åŒ–
    prediction_real = processor.scaler.inverse_transform(full_prediction)
    predicted_price = prediction_real[0, 3]
    
    return predicted_price


def predict_multiple_steps(model, X, processor, steps):
    """é¢„æµ‹æœªæ¥å¤šä¸ªæ—¶é—´æ­¥"""
    predictions = []
    current_X = X.copy()
    
    for i in range(steps):
        # é¢„æµ‹ä¸‹ä¸€ä¸ªå€¼
        prediction_scaled = model.predict(current_X, verbose=0)
        predictions.append(prediction_scaled[0, 0])
        
        # æ›´æ–°è¾“å…¥ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
        # å°†æ–°é¢„æµ‹æ·»åŠ åˆ°åºåˆ—æœ«å°¾ï¼Œç§»é™¤æœ€æ—§çš„æ•°æ®ç‚¹
        new_point = current_X[0, -1, :].copy()  # å¤åˆ¶æœ€åä¸€ä¸ªç‚¹çš„æ‰€æœ‰ç‰¹å¾
        new_point[3] = prediction_scaled[0, 0]  # æ›´æ–°closeå€¼
        
        # æ»šåŠ¨çª—å£
        current_X = np.roll(current_X, -1, axis=1)
        current_X[0, -1, :] = new_point
    
    # åå½’ä¸€åŒ–æ‰€æœ‰é¢„æµ‹
    predictions_array = np.array(predictions).reshape(-1, 1)
    full_predictions = np.zeros((len(predictions), len(processor.feature_columns)))
    full_predictions[:, 3] = predictions_array.flatten()
    
    predictions_real = processor.scaler.inverse_transform(full_predictions)
    predicted_prices = predictions_real[:, 3]
    
    return predicted_prices


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='LSTMä»·æ ¼é¢„æµ‹è„šæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # é¢„æµ‹ä¸‹ä¸€ä¸ªä»·æ ¼
  python predict_lstm.py
  
  # é¢„æµ‹æœªæ¥24å°æ—¶
  python predict_lstm.py --steps 24
  
  # é¢„æµ‹ETHä»·æ ¼
  python predict_lstm.py --symbol ETHUSDT
  
  # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
  python predict_lstm.py --verbose
        """
    )
    
    parser.add_argument(
        '--symbol',
        type=str,
        default=DataConfig.SYMBOL,
        help=f'äº¤æ˜“å¯¹ç¬¦å· (é»˜è®¤: {DataConfig.SYMBOL})'
    )
    
    parser.add_argument(
        '--steps',
        type=int,
        default=1,
        help='é¢„æµ‹æœªæ¥å¤šå°‘ä¸ªæ—¶é—´æ­¥ (é»˜è®¤: 1)'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯'
    )
    
    args = parser.parse_args()
    
    print("="*70)
    print(" "*20 + "ğŸ”® LSTM ä»·æ ¼é¢„æµ‹")
    print("="*70)
    print(f"\näº¤æ˜“å¯¹: {args.symbol}")
    print(f"é¢„æµ‹æ­¥æ•°: {args.steps}")
    print("="*70)
    
    # 1. åŠ è½½æ¨¡å‹å’Œscaler
    print("\nâš™ï¸ æ­¥éª¤ 1: åŠ è½½æ¨¡å‹")
    model, processor = load_model_and_scaler()
    
    if args.verbose:
        print("\næ¨¡å‹æ¶æ„:")
        model.summary()
    
    # 2. å‡†å¤‡æœ€æ–°æ•°æ®
    print("\nâš™ï¸ æ­¥éª¤ 2: å‡†å¤‡æ•°æ®")
    X, df_original = prepare_recent_data(
        processor, 
        args.symbol, 
        DataConfig.INTERVAL,
        DataConfig.TIME_STEPS
    )
    
    # 3. è¿›è¡Œé¢„æµ‹
    print("\nâš™ï¸ æ­¥éª¤ 3: è¿›è¡Œé¢„æµ‹")
    
    if args.steps == 1:
        # å•æ­¥é¢„æµ‹
        predicted_price = predict_next_price(model, X, processor)
        
        # è·å–å½“å‰ä»·æ ¼
        current_price = df_original['close'].iloc[-1]
        
        # è®¡ç®—å˜åŒ–
        price_change = predicted_price - current_price
        price_change_pct = (price_change / current_price) * 100
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "="*70)
        print("ğŸ“Š é¢„æµ‹ç»“æœ")
        print("="*70)
        print(f"\nå½“å‰ä»·æ ¼: ${current_price:.2f}")
        print(f"é¢„æµ‹ä»·æ ¼: ${predicted_price:.2f}")
        print(f"\nä»·æ ¼å˜åŒ–: ${price_change:+.2f} ({price_change_pct:+.2f}%)")
        
        if price_change > 0:
            print(f"\nğŸ“ˆ é¢„æµ‹: ä»·æ ¼ä¸Šæ¶¨")
            trend_emoji = "ğŸš€"
        else:
            print(f"\nğŸ“‰ é¢„æµ‹: ä»·æ ¼ä¸‹è·Œ")
            trend_emoji = "â¬‡ï¸"
        
        print(f"\n{trend_emoji} è¶‹åŠ¿ä¿¡å·: {'çœ‹æ¶¨' if price_change > 0 else 'çœ‹è·Œ'}")
        print("="*70)
        
    else:
        # å¤šæ­¥é¢„æµ‹
        predicted_prices = predict_multiple_steps(model, X, processor, args.steps)
        
        # å½“å‰ä»·æ ¼
        current_price = df_original['close'].iloc[-1]
        
        # åˆ›å»ºé¢„æµ‹ç»“æœDataFrame
        future_times = []
        current_time = df_original['timestamp'].iloc[-1]
        
        # è®¡ç®—æ—¶é—´é—´éš”
        interval_minutes = {
            '1m': 1, '5m': 5, '15m': 15, '30m': 30,
            '1h': 60, '2h': 120, '4h': 240, '1d': 1440
        }.get(DataConfig.INTERVAL, 60)
        
        for i in range(1, args.steps + 1):
            future_time = current_time + timedelta(minutes=interval_minutes * i)
            future_times.append(future_time)
        
        predictions_df = pd.DataFrame({
            'timestamp': future_times,
            'predicted_price': predicted_prices,
            'change_from_current': predicted_prices - current_price,
            'change_pct': ((predicted_prices - current_price) / current_price) * 100
        })
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "="*70)
        print(f"ğŸ“Š æœªæ¥ {args.steps} ä¸ªæ—¶é—´ç‚¹çš„é¢„æµ‹")
        print("="*70)
        print(f"\nå½“å‰ä»·æ ¼: ${current_price:.2f}")
        print(f"å½“å‰æ—¶é—´: {current_time}")
        print("\né¢„æµ‹ç»“æœ:")
        print(predictions_df.to_string(index=False))
        
        # æ€»ä½“è¶‹åŠ¿
        final_price = predicted_prices[-1]
        total_change = final_price - current_price
        total_change_pct = (total_change / current_price) * 100
        
        print(f"\n" + "-"*70)
        print(f"æœ€ç»ˆé¢„æµ‹ä»·æ ¼: ${final_price:.2f}")
        print(f"æ€»ä½“å˜åŒ–: ${total_change:+.2f} ({total_change_pct:+.2f}%)")
        
        if total_change > 0:
            print(f"ğŸ“ˆ æ€»ä½“è¶‹åŠ¿: ä¸Šæ¶¨ ğŸš€")
        else:
            print(f"ğŸ“‰ æ€»ä½“è¶‹åŠ¿: ä¸‹è·Œ â¬‡ï¸")
        
        print("="*70)
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        save_path = os.path.join(PathConfig.RESULTS_DIR, f'predictions_{args.symbol}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv')
        predictions_df.to_csv(save_path, index=False)
        print(f"\nğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜: {save_path}")
    
    # å…è´£å£°æ˜
    print("\n" + "="*70)
    print("âš ï¸  å…è´£å£°æ˜")
    print("="*70)
    print("æœ¬é¢„æµ‹ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚")
    print("åŠ å¯†è´§å¸äº¤æ˜“å­˜åœ¨é«˜é£é™©ï¼Œè¯·è°¨æ…å†³ç­–ã€‚")
    print("å†å²æ•°æ®ä¸èƒ½ä¿è¯æœªæ¥è¡¨ç°ã€‚")
    print("="*70)


if __name__ == "__main__":
    main()
